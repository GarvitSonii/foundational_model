{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9054a3d4-4de5-4275-b16f-25d7048d10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, random, os, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from models import UNetSmall\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09684d6b-3dae-496f-86a3-ebcbfd344c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(multiprocessing.cpu_count())  # e.g., 16\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fb9925-722e-49ac-bcec-db5b78bdafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_val_split.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "train_samples, val_samples = data[\"train\"], data[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0e8ded-a2a7-4684-ac7d-3fd8a47893a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21041 5260\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples), len(val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c784d6f-fe46-4a10-8cb2-b294735da865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cloud95Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, items, tilesize=None, augment=False):\n",
    "        self.items = items\n",
    "        self.tilesize = tilesize\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.items)\n",
    "\n",
    "    def _read_band(self, p: Path):\n",
    "        arr = np.array(Image.open(p), dtype=np.uint8).astype(np.float32)\n",
    "        return arr / 255.0\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rec = self.items[i]\n",
    "        R = self._read_band(rec[\"r\"])\n",
    "        G = self._read_band(rec[\"g\"])\n",
    "        B = self._read_band(rec[\"b\"])\n",
    "        N = self._read_band(rec[\"n\"])\n",
    "        M = np.array(Image.open(rec[\"m\"]).convert(\"L\")).astype(np.uint8)\n",
    "        M = (M > 0).astype(np.float32)\n",
    "\n",
    "        # Optional random 512 crop (most are 512 already; keep robust)\n",
    "        H, W = R.shape\n",
    "        if self.tilesize and (H >= self.tilesize and W >= self.tilesize):\n",
    "            s = self.tilesize\n",
    "            # x = 0 if W == s else random.randint(0, W - s)\n",
    "            # y = 0 if H == s else random.randint(0, H - s)\n",
    "            # R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "\n",
    "            if self.augment:\n",
    "                x = 0 if W == s else random.randint(0, W - s)\n",
    "                y = 0 if H == s else random.randint(0, H - s)\n",
    "            else:\n",
    "                x = (W - s) // 2\n",
    "                y = (H - s) // 2\n",
    "                \n",
    "            R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "        \n",
    "        \n",
    "        # Simple flips as light augmentation\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.fliplr(R), np.fliplr(G), np.fliplr(B), np.fliplr(N), np.fliplr(M)\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.flipud(R), np.flipud(G), np.flipud(B), np.flipud(N), np.flipud(M)\n",
    "\n",
    "        img = np.stack([R,G,B,N], axis=0).astype(np.float32)        # (4,H,W)\n",
    "        msk = M[None, ...].astype(np.float32)                        # (1,H,W)\n",
    "\n",
    "        \n",
    "        return torch.from_numpy(img), torch.from_numpy(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0f2c4c-1602-4118-af93-5df2a9f706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6): super().__init__(); self.eps = eps\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2 * (probs*targets).sum(dim=(1,2,3))\n",
    "        den = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        return (1 - (num + self.eps)/(den + self.eps)).mean()\n",
    "\n",
    "def iou_binary(logits, targets, thr=0.5):\n",
    "    p = (torch.sigmoid(logits) > thr).float()\n",
    "    inter = (p*targets).sum(dim=(1,2,3))\n",
    "    union = (p + targets - p*targets).sum(dim=(1,2,3))\n",
    "    return ((inter+1e-6)/(union+1e-6)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfefa5-0736-458c-93a9-1a0eb08eaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilesize = 128 \n",
    "train_ds = Cloud95Dataset(\n",
    "    train_samples, \n",
    "    tilesize=tilesize, \n",
    "    augment=True\n",
    ")\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,            # smaller batch to start\n",
    "    shuffle=True,\n",
    "    num_workers=0,           # <-- key\n",
    "    pin_memory=False,        # pinning helps GPU, can slow CPU-only\n",
    "    persistent_workers=False # <-- key\n",
    ")\n",
    "val_ds = Cloud95Dataset(\n",
    "    val_samples, \n",
    "    tilesize=tilesize, \n",
    "    augment=False\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=8,            # smaller batch to start\n",
    "    shuffle=False,\n",
    "    num_workers=0,           # <-- key\n",
    "    pin_memory=False,        # pinning helps GPU, can slow CPU-only\n",
    "    persistent_workers=False # <-- key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bedbf-ae22-4665-9c50-8e6754cda8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNetSmall(in_ch=4, out_ch=1).to(device)\n",
    "\n",
    "bce, dice = nn.BCEWithLogitsLoss(), DiceLoss()\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456fb57-17fd-420a-a53d-77f50881ef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "batch 2631"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 20\n",
    "print('begin training')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    n_batches = 0\n",
    "    pbar = tqdm(train_dl, desc=f'Epoch {epoch}/{epochs} - train', leave=False)\n",
    "    for imgs, masks in pbar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        pbar.set_postfix({'loss': f'{train_loss / n_batches:.4f}', 'lr': opt.param_groups[0]['lr']})\n",
    "\n",
    "    sched.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    n_val = 0\n",
    "    with torch.no_grad():\n",
    "        pbarv = tqdm(val_dl, desc=f'Epoch {epoch}/{epochs} - val', leave=False)\n",
    "        for imgs, masks in pbarv:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "            val_loss += loss.item()\n",
    "            val_iou += iou_binary(logits, masks)\n",
    "            n_val += 1\n",
    "            pbarv.set_postfix({'val_loss': f'{val_loss / n_val:.4f}', 'val_iou': f'{val_iou / n_val:.4f}'})\n",
    "\n",
    "    avg_train_loss = train_loss / max(1, n_batches)\n",
    "    avg_val_loss = val_loss / max(1, n_val)\n",
    "    avg_val_iou = val_iou / max(1, n_val)\n",
    "\n",
    "    print(f'Epoch {epoch}/{epochs}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}, val_iou={avg_val_iou:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    # save model for this epoch\n",
    "    ep_path = f\"model_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'iou': avg_val_iou,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': opt.state_dict(),\n",
    "        \"sched_state\": sched.state_dict(),\n",
    "    }, ep_path)\n",
    "    print(f'Saved epoch model: {ep_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea0b0ff-d419-4e40-90b2-500e3efe13b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as unet_cloud95.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    \"best_iou\": best_iou,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": opt.state_dict(),\n",
    "}, best_path)\n",
    "\n",
    "print(f\"Model saved as {best_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66344-5b2c-49db-9824-8a0b2364ea06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
