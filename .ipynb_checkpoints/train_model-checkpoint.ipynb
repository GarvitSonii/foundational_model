{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9054a3d4-4de5-4275-b16f-25d7048d10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import UNetSmall\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09684d6b-3dae-496f-86a3-ebcbfd344c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\n\u001b[32m      2\u001b[39m torch.set_num_threads(multiprocessing.cpu_count())  \u001b[38;5;66;03m# e.g., 16\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_num_interop_threads\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m torch.set_float32_matmul_precision(\u001b[33m'\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(multiprocessing.cpu_count())  # e.g., 16\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb9925-722e-49ac-bcec-db5b78bdafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"train_val_split.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "train_samples, val_samples = data[\"train\"], data[\"val\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c784d6f-fe46-4a10-8cb2-b294735da865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) Dataset =====\n",
    "class Cloud95Dataset(Dataset):\n",
    "    def __init__(self, items, tilesize=None, augment=False):\n",
    "        self.items = items\n",
    "        self.tilesize = tilesize\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    # def _read_band(self, p: Path):\n",
    "    #     arr = np.array(Image.open(p))\n",
    "    #     arr = arr.astype(np.float32)\n",
    "    #     # Normalize: if looks like 8-bit, /255; else use /10000 (typical S2 scaling)\n",
    "    #     maxv = arr.max() if arr.size else 255\n",
    "    #     if maxv <= 255: arr = arr / 255.0\n",
    "    #     else: arr = np.clip(arr / 10000.0, 0.0, 1.5)\n",
    "    #     return arr\n",
    "\n",
    "    def _read_band(self, p: Path):\n",
    "        arr = np.array(Image.open(p), dtype=np.uint8).astype(np.float32)\n",
    "        return arr / 255.0\n",
    "\n",
    "    \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rec = self.items[i]\n",
    "        R = self._read_band(rec[\"r\"])\n",
    "        G = self._read_band(rec[\"g\"])\n",
    "        B = self._read_band(rec[\"b\"])\n",
    "        N = self._read_band(rec[\"n\"])\n",
    "        M = np.array(Image.open(rec[\"m\"]).convert(\"L\")).astype(np.uint8)\n",
    "        M = (M > 0).astype(np.float32)\n",
    "\n",
    "        # Optional random 512 crop (most are 512 already; keep robust)\n",
    "        H, W = R.shape\n",
    "        if self.tilesize and (H >= self.tilesize and W >= self.tilesize):\n",
    "            s = self.tilesize\n",
    "            # x = 0 if W == s else random.randint(0, W - s)\n",
    "            # y = 0 if H == s else random.randint(0, H - s)\n",
    "            # R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "\n",
    "            if self.augment:\n",
    "                x = 0 if W == s else random.randint(0, W - s)\n",
    "                y = 0 if H == s else random.randint(0, H - s)\n",
    "            else:\n",
    "                x = (W - s) // 2\n",
    "                y = (H - s) // 2\n",
    "                \n",
    "            R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "        # Simple flips as light augmentation\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.fliplr(R), np.fliplr(G), np.fliplr(B), np.fliplr(N), np.fliplr(M)\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.flipud(R), np.flipud(G), np.flipud(B), np.flipud(N), np.flipud(M)\n",
    "\n",
    "        img = np.stack([R,G,B,N], axis=0).astype(np.float32)        # (4,H,W)\n",
    "        msk = M[None, ...].astype(np.float32)                        # (1,H,W)\n",
    "        return torch.from_numpy(img), torch.from_numpy(msk)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0f2c4c-1602-4118-af93-5df2a9f706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 5) Loss, metrics, training =====\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6): super().__init__(); self.eps = eps\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2 * (probs*targets).sum(dim=(1,2,3))\n",
    "        den = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        return (1 - (num + self.eps)/(den + self.eps)).mean()\n",
    "\n",
    "def iou_binary(logits, targets, thr=0.5):\n",
    "    p = (torch.sigmoid(logits) > thr).float()\n",
    "    inter = (p*targets).sum(dim=(1,2,3))\n",
    "    union = (p + targets - p*targets).sum(dim=(1,2,3))\n",
    "    return ((inter+1e-6)/(union+1e-6)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdfefa5-0736-458c-93a9-1a0eb08eaf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: using 2104/21041 train and 526/5260 val samples\n"
     ]
    }
   ],
   "source": [
    "# Datasets & loaders\n",
    "tile = 128  # chips are typically 512; keep same\n",
    "train_ds = Cloud95Dataset(train_samples, tilesize=tile, augment=True)\n",
    "val_ds   = Cloud95Dataset(val_samples,   tilesize=tile, augment=False)\n",
    "# train_ds.tilesize = 256\n",
    "# val_ds.tilesize   = 256\n",
    "\n",
    "# === Debug subset mode ===\n",
    "DEBUG_FRACTION = 0.1  # load only 1/10th of dataset\n",
    "if DEBUG_FRACTION < 1.0:\n",
    "    from torch.utils.data import Subset\n",
    "    import random\n",
    "    n_train = int(len(train_ds) * DEBUG_FRACTION)\n",
    "    n_val   = int(len(val_ds) * DEBUG_FRACTION)\n",
    "    subset_train_idx = random.sample(range(len(train_ds)), n_train)\n",
    "    subset_val_idx   = random.sample(range(len(val_ds)), n_val)\n",
    "    train_ds = Subset(train_ds, subset_train_idx)\n",
    "    val_ds   = Subset(val_ds, subset_val_idx)\n",
    "    print(f\"Debug mode: using {n_train}/{len(train_samples)} train and {n_val}/{len(val_samples)} val samples\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetSmall(in_ch=4, out_ch=1).to(device)\n",
    "bce, dice = nn.BCEWithLogitsLoss(), DiceLoss()\n",
    "criterion = nn.BCEWithLogitsLoss() #comment\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
    "\n",
    "best_iou, best_path = 0.0, \"unet_cloud95.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ad360f-e6da-45c7-adec-b91096e15a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_ds) = 2104\n",
      "one sample shapes: torch.Size([4, 128, 128]) torch.Size([1, 128, 128]) took 0.3 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "print(\"len(train_ds) =\", len(train_ds))\n",
    "img, msk = train_ds[0]   # direct call bypasses DataLoader workers\n",
    "print(\"one sample shapes:\", img.shape, msk.shape, \"took\", round(time.time()-t0, 2), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d51fef4-84ba-4416-8b0c-8ec2ac0551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,            # smaller batch to start\n",
    "    shuffle=True,\n",
    "    num_workers=0,           # <-- key\n",
    "    pin_memory=False,        # pinning helps GPU, can slow CPU-only\n",
    "    persistent_workers=False # <-- key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c456fb57-17fd-420a-a53d-77f50881ef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "batch 263\n",
      "end of epoch in 284.4 s\n"
     ]
    }
   ],
   "source": [
    "print('begin training')\n",
    "model.train()\n",
    "t0 = time.time()\n",
    "\n",
    "for batch_i, (imgs, masks) in enumerate(train_dl, 1):\n",
    "    print(f\"\\rbatch {batch_i}\", end='', flush=True)  # prints as soon as first batch arrives\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "    logits = model(imgs)\n",
    "    loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "print(\"\\nend of epoch in\", round(time.time()-t0, 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea0b0ff-d419-4e40-90b2-500e3efe13b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as unet_cloud95.pt\n"
     ]
    }
   ],
   "source": [
    "# Save model weights (and optional optimizer/metadata)\n",
    "epoch=1\n",
    "torch.save({\n",
    "    \"epoch\": epoch,\n",
    "    \"best_iou\": best_iou,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": opt.state_dict(),\n",
    "}, best_path)\n",
    "\n",
    "print(f\"Model saved as {best_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66344-5b2c-49db-9824-8a0b2364ea06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
