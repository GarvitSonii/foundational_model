{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da77bf1-a7a3-4b39-b496-3060adb803bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, random, os, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from Vit import CloudSegSpectralViT\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad94a5-4f69-4b0a-8174-95f19c60b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(multiprocessing.cpu_count())  # e.g., 16\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564e64d-0f42-4a7d-a935-6a955cefed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_val_split.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "train_samples, val_samples = data[\"train\"], data[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c915406-a472-446c-bb10-d6a7d1a8fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_samples), len(val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a88be-df6e-4e15-8c4f-42f083df9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cloud95Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, items, tilesize=None, augment=False):\n",
    "        self.items = items\n",
    "        self.tilesize = tilesize\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.items)\n",
    "\n",
    "    def _read_band(self, p: Path):\n",
    "        arr = np.array(Image.open(p), dtype=np.uint8).astype(np.float32)\n",
    "        return arr / 255.0\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rec = self.items[i]\n",
    "        R = self._read_band(rec[\"r\"])\n",
    "        G = self._read_band(rec[\"g\"])\n",
    "        B = self._read_band(rec[\"b\"])\n",
    "        N = self._read_band(rec[\"n\"])\n",
    "        M = np.array(Image.open(rec[\"m\"]).convert(\"L\")).astype(np.uint8)\n",
    "        M = (M > 0).astype(np.float32)\n",
    "\n",
    "        # Optional random 512 crop (most are 512 already; keep robust)\n",
    "        H, W = R.shape\n",
    "        if self.tilesize and (H >= self.tilesize and W >= self.tilesize):\n",
    "            s = self.tilesize\n",
    "            # x = 0 if W == s else random.randint(0, W - s)\n",
    "            # y = 0 if H == s else random.randint(0, H - s)\n",
    "            # R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "\n",
    "            if self.augment:\n",
    "                x = 0 if W == s else random.randint(0, W - s)\n",
    "                y = 0 if H == s else random.randint(0, H - s)\n",
    "            else:\n",
    "                x = (W - s) // 2\n",
    "                y = (H - s) // 2\n",
    "                \n",
    "            R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "        \n",
    "        \n",
    "        # Simple flips as light augmentation\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.fliplr(R), np.fliplr(G), np.fliplr(B), np.fliplr(N), np.fliplr(M)\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.flipud(R), np.flipud(G), np.flipud(B), np.flipud(N), np.flipud(M)\n",
    "\n",
    "        img = np.stack([R,G,B,N], axis=0).astype(np.float32)        # (4,H,W)\n",
    "        msk = M[None, ...].astype(np.float32)                        # (1,H,W)\n",
    "\n",
    "        \n",
    "        return torch.from_numpy(img), torch.from_numpy(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9fb18-4299-44a4-a0f0-eb2965d0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6): super().__init__(); self.eps = eps\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2 * (probs*targets).sum(dim=(1,2,3))\n",
    "        den = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        return (1 - (num + self.eps)/(den + self.eps)).mean()\n",
    "\n",
    "def iou_binary(logits, targets, thr=0.5):\n",
    "    p = (torch.sigmoid(logits) > thr).float()\n",
    "    inter = (p*targets).sum(dim=(1,2,3))\n",
    "    union = (p + targets - p*targets).sum(dim=(1,2,3))\n",
    "    return ((inter+1e-6)/(union+1e-6)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5252d75-b06c-4131-ba22-773fc5c73c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilesize = 128 \n",
    "train_ds = Cloud95Dataset(\n",
    "    train_samples, \n",
    "    tilesize=tilesize, \n",
    "    augment=True\n",
    ")\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,            # smaller batch to start\n",
    "    shuffle=True,\n",
    "    num_workers=0,           # <-- key\n",
    "    pin_memory=False,        # pinning helps GPU, can slow CPU-only\n",
    "    persistent_workers=False # <-- key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc9629-d218-4f9d-8e93-b1029b8003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CloudSegSpectralViT(\n",
    "    in_ch=4,            # RGB+NIR as in Cloud95\n",
    "    num_classes=1,      # or 2 if you prefer CE\n",
    "    patch_size=(8,8),   # matches paper\n",
    "    spec_group=3,       # 3D token grouping; works with 4ch (pads 1 ch internally)\n",
    "    depth=8, embed_dim=384, num_heads=6  # lighter starting point\n",
    ").to(device)\n",
    "\n",
    "bce, dice = nn.BCEWithLogitsLoss(), DiceLoss()\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
    "\n",
    "best_iou, best_path = 0.0, \"unet_cloud95.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14666ec0-8631-40d4-8331-aec1ad863942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for imgs, masks in train_loader:         # imgs: (B,4,H,W), masks: (B,1,H,W) or (B,H,W)\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "    # (ViT only) pad to 8x\n",
    "    imgs, ph, pw = pad_to_multiple(imgs, 8)\n",
    "    if model_out_is_binary:  # num_classes=1\n",
    "        masks, _, _ = pad_to_multiple(masks.float(), 8)  # keep as float for BCE\n",
    "    else:\n",
    "        masks, _, _ = pad_to_multiple(masks, 8)\n",
    "\n",
    "    logits = model(imgs)\n",
    "    if model_out_is_binary:\n",
    "        loss = criterion(logits, masks)  # BCEWithLogitsLoss expects same shape\n",
    "    else:\n",
    "        loss = criterion(logits, masks.squeeze(1).long())  # CE expects (B,H,W) long\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
