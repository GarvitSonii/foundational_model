{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541d79c1-6167-404e-8645-c7e26b42f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished imports\n"
     ]
    }
   ],
   "source": [
    "# ===== 0) Config =====\n",
    "from pathlib import Path\n",
    "import re, random, os, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print('finished imports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8246a95c-7c8e-499a-9475-1bd98a28e5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "torch.set_num_threads(multiprocessing.cpu_count())  # e.g., 16\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe667fe9-3cb9-446c-bac4-88934b76ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path saved to root\n"
     ]
    }
   ],
   "source": [
    "root = Path(r\"C:\\Users\\garvi\\.cache\\kagglehub\\datasets\\sorour\\95cloud-cloud-segmentation-on-satellite-images\\versions\\3\\95-cloud_training_only_additional_to38-cloud\")\n",
    "print('path saved to root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81edd29c-f048-4a10-9115-0ad022fdcd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "# exact subfolders as seen in your output\n",
    "RED   = root / \"train_red_additional_to38cloud\"\n",
    "GREEN = root / \"train_green_additional_to38cloud\"\n",
    "BLUE  = root / \"train_blue_additional_to38cloud\"\n",
    "NIR   = root / \"train_nir_additional_to38cloud\"\n",
    "GT    = root / \"train_gt_additional_to38cloud\"\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26387e74-c9ae-4bba-a2c9-4162d18992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RED.exists() and GREEN.exists() and BLUE.exists() and NIR.exists() and GT.exists(), \"One or more band/GT folders missing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58c8036-8f2c-476b-8a1a-39d7bc5b07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Pair files by base key (strip '_red/_green/_nir/_gt' tokens) =====\n",
    "IMG_EXT = (\".tif\",\".tiff\",\".png\",\".jpg\",\".jpeg\")\n",
    "MSK_EXT = (\".tif\",\".tiff\",\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b4ccb8-d466-4586-8362-87ff9fc6b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_token = re.compile(r\"(?:^|[_\\-])(red|green|blue|nir|gt|mask|label)(?:$|[_\\-])\", re.I)\n",
    "def norm_stem(p: Path) -> str:\n",
    "    s = p.stem\n",
    "    s = _token.sub(\"_\", s)\n",
    "    s = re.sub(r\"[_\\-]+\", \"_\", s).strip(\"_-\")\n",
    "    return s.lower()\n",
    "\n",
    "def list_files(folder, exts):\n",
    "    return [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in exts]\n",
    "\n",
    "R = list_files(RED, IMG_EXT)\n",
    "G = list_files(GREEN, IMG_EXT)\n",
    "B = list_files(BLUE, IMG_EXT)\n",
    "N = list_files(NIR, IMG_EXT)\n",
    "M = list_files(GT,  MSK_EXT)\n",
    "\n",
    "def index(files):\n",
    "    d = {}\n",
    "    for p in files:\n",
    "        d.setdefault(norm_stem(p), []).append(p)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84f525c-1b5e-4eee-b454-7a176c068dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26301 paired chips.\n"
     ]
    }
   ],
   "source": [
    "R_idx, G_idx, B_idx, N_idx, M_idx = map(index, (R,G,B,N,M))\n",
    "keys = set(R_idx) & set(G_idx) & set(B_idx) & set(N_idx) & set(M_idx)\n",
    "keys = sorted(list(keys))\n",
    "print(f\"Found {len(keys)} paired chips.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ae3a34-c523-407d-823f-614d4da4a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for k in keys:\n",
    "    pairs.append({\n",
    "        \"r\": R_idx[k][0], \"g\": G_idx[k][0], \"b\": B_idx[k][0], \"n\": N_idx[k][0], \"m\": M_idx[k][0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51eab682-24f5-47f3-806a-29880e0c9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 21041  Val: 5260\n"
     ]
    }
   ],
   "source": [
    "# ===== 2) Train/val split =====\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "val_frac = 0.2\n",
    "n_val = int(len(pairs)*val_frac)\n",
    "val_samples = pairs[:n_val]\n",
    "train_samples = pairs[n_val:]\n",
    "print(f\"Train: {len(train_samples)}  Val: {len(val_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91946a49-c9d8-4cb4-8bdf-d2d45fdfad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) Dataset =====\n",
    "class Cloud95Dataset(Dataset):\n",
    "    def __init__(self, items, tilesize=None, augment=False):\n",
    "        self.items = items\n",
    "        self.tilesize = tilesize\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    # def _read_band(self, p: Path):\n",
    "    #     arr = np.array(Image.open(p))\n",
    "    #     arr = arr.astype(np.float32)\n",
    "    #     # Normalize: if looks like 8-bit, /255; else use /10000 (typical S2 scaling)\n",
    "    #     maxv = arr.max() if arr.size else 255\n",
    "    #     if maxv <= 255: arr = arr / 255.0\n",
    "    #     else: arr = np.clip(arr / 10000.0, 0.0, 1.5)\n",
    "    #     return arr\n",
    "\n",
    "    def _read_band(self, p: Path):\n",
    "        arr = np.array(Image.open(p), dtype=np.uint8).astype(np.float32)\n",
    "        return arr / 255.0\n",
    "\n",
    "    \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rec = self.items[i]\n",
    "        R = self._read_band(rec[\"r\"])\n",
    "        G = self._read_band(rec[\"g\"])\n",
    "        B = self._read_band(rec[\"b\"])\n",
    "        N = self._read_band(rec[\"n\"])\n",
    "        M = np.array(Image.open(rec[\"m\"]).convert(\"L\")).astype(np.uint8)\n",
    "        M = (M > 0).astype(np.float32)\n",
    "\n",
    "        # Optional random 512 crop (most are 512 already; keep robust)\n",
    "        H, W = R.shape\n",
    "        if self.tilesize and (H >= self.tilesize and W >= self.tilesize):\n",
    "            s = self.tilesize\n",
    "            # x = 0 if W == s else random.randint(0, W - s)\n",
    "            # y = 0 if H == s else random.randint(0, H - s)\n",
    "            # R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "\n",
    "            if self.augment:\n",
    "                x = 0 if W == s else random.randint(0, W - s)\n",
    "                y = 0 if H == s else random.randint(0, H - s)\n",
    "            else:\n",
    "                x = (W - s) // 2\n",
    "                y = (H - s) // 2\n",
    "                \n",
    "            R, G, B, N, M = R[y:y+s, x:x+s], G[y:y+s, x:x+s], B[y:y+s, x:x+s], N[y:y+s, x:x+s], M[y:y+s, x:x+s]\n",
    "        # Simple flips as light augmentation\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.fliplr(R), np.fliplr(G), np.fliplr(B), np.fliplr(N), np.fliplr(M)\n",
    "        if self.augment and random.random() < 0.5:\n",
    "            R, G, B, N, M = np.flipud(R), np.flipud(G), np.flipud(B), np.flipud(N), np.flipud(M)\n",
    "\n",
    "        img = np.stack([R,G,B,N], axis=0).astype(np.float32)        # (4,H,W)\n",
    "        msk = M[None, ...].astype(np.float32)                        # (1,H,W)\n",
    "        return torch.from_numpy(img), torch.from_numpy(msk)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86036fb5-f47f-445b-a546-3ce851077800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, groups=8):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self, in_ch=4, out_ch=1):\n",
    "        super().__init__()\n",
    "        # slimmer channels help a lot on CPU\n",
    "        ch = [24, 48, 96, 192]\n",
    "        self.down1 = DoubleConv(in_ch, ch[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.down2 = DoubleConv(ch[0], ch[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.down3 = DoubleConv(ch[1], ch[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bottom = DoubleConv(ch[2], ch[3])\n",
    "\n",
    "        def up(in_c, skip_c, out_c):\n",
    "            return nn.ModuleDict({\n",
    "                \"up\": nn.Sequential(nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "                                    nn.Conv2d(in_c, out_c, 1, bias=False)),\n",
    "                \"dec\": DoubleConv(out_c + skip_c, out_c)\n",
    "            })\n",
    "        self.up3 = up(ch[3], ch[2], ch[2])\n",
    "        self.up2 = up(ch[2], ch[1], ch[1])\n",
    "        self.up1 = up(ch[1], ch[0], ch[0])\n",
    "        self.head = nn.Conv2d(ch[0], out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.down1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.down2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.down3(p2); p3 = self.pool3(c3)\n",
    "        cb = self.bottom(p3)\n",
    "\n",
    "        u3 = self.up3[\"up\"](cb); d3 = self.up3[\"dec\"](torch.cat([u3, c3], 1))\n",
    "        u2 = self.up2[\"up\"](d3); d2 = self.up2[\"dec\"](torch.cat([u2, c2], 1))\n",
    "        u1 = self.up1[\"up\"](d2); d1 = self.up1[\"dec\"](torch.cat([u1, c1], 1))\n",
    "        return self.head(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af2cc54-bf4d-4103-8bf8-de527b3b6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 4) U-Net (small) =====\n",
    "# class DoubleConv(nn.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "#         )\n",
    "#     def forward(self, x): return self.net(x)\n",
    "\n",
    "# class UNetSmall(nn.Module):\n",
    "#     def __init__(self, in_ch=4, out_ch=1):\n",
    "#         super().__init__()\n",
    "#         self.down1 = DoubleConv(in_ch, 32)\n",
    "#         self.pool1 = nn.MaxPool2d(2)\n",
    "#         self.down2 = DoubleConv(32, 64)\n",
    "#         self.pool2 = nn.MaxPool2d(2)\n",
    "#         self.down3 = DoubleConv(64, 128)\n",
    "#         self.pool3 = nn.MaxPool2d(2)\n",
    "#         self.bottom = DoubleConv(128, 256)\n",
    "#         self.up3 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "#         self.dec3 = DoubleConv(256, 128)\n",
    "#         self.up2 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "#         self.dec2 = DoubleConv(128, 64)\n",
    "#         self.up1 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
    "#         self.dec1 = DoubleConv(64, 32)\n",
    "#         self.head = nn.Conv2d(32, out_ch, 1)\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     c1 = self.down1(x)         # (B,32,H,W)\n",
    "    #     p1 = self.pool1(c1)        # (B,32,H/2,W/2)\n",
    "    #     c2 = self.down2(p1)        # (B,64, ...)\n",
    "    #     p2 = self.pool2(c2)\n",
    "    #     c3 = self.down3(p2)        # (B,128,...)\n",
    "    #     p3 = self.pool3(c3)\n",
    "    #     cb = self.bottom(p3)       # (B,256,...)\n",
    "    #     u3 = self.up3(cb)          # -> match c3\n",
    "    #     d3 = self.dec3(torch.cat([u3, c3], dim=1))\n",
    "    #     u2 = self.up2(d3)\n",
    "    #     d2 = self.dec2(torch.cat([u2, c2], dim=1))\n",
    "    #     u1 = self.up1(d2)\n",
    "    #     d1 = self.dec1(torch.cat([u1, c1], dim=1))\n",
    "    #     return self.head(d1)       # logits (B,1,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d24289-0167-44f7-acbf-0fb340af3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 5) Loss, metrics, training =====\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6): super().__init__(); self.eps = eps\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2 * (probs*targets).sum(dim=(1,2,3))\n",
    "        den = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        return (1 - (num + self.eps)/(den + self.eps)).mean()\n",
    "\n",
    "def iou_binary(logits, targets, thr=0.5):\n",
    "    p = (torch.sigmoid(logits) > thr).float()\n",
    "    inter = (p*targets).sum(dim=(1,2,3))\n",
    "    union = (p + targets - p*targets).sum(dim=(1,2,3))\n",
    "    return ((inter+1e-6)/(union+1e-6)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954ecd73-acc3-42e5-993c-df1d80524df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets & loaders\n",
    "tile = 128  # chips are typically 512; keep same\n",
    "train_ds = Cloud95Dataset(train_samples, tilesize=tile, augment=True)\n",
    "val_ds   = Cloud95Dataset(val_samples,   tilesize=tile, augment=False)\n",
    "# train_ds.tilesize = 256\n",
    "# val_ds.tilesize   = 256\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetSmall(in_ch=4, out_ch=1).to(device)\n",
    "bce, dice = nn.BCEWithLogitsLoss(), DiceLoss()\n",
    "criterion = nn.BCEWithLogitsLoss() #comment\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
    "\n",
    "best_iou, best_path = 0.0, \"unet_cloud95.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5d4d06-cf48-4c32-b5ff-36c5daa63330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_ds) = 21041\n",
      "one sample shapes: torch.Size([4, 128, 128]) torch.Size([1, 128, 128]) took 0.29 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "print(\"len(train_ds) =\", len(train_ds))\n",
    "img, msk = train_ds[0]   # direct call bypasses DataLoader workers\n",
    "print(\"one sample shapes:\", img.shape, msk.shape, \"took\", round(time.time()-t0, 2), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b987d5af-1cba-4c4d-b594-dbbe4665f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,            # smaller batch to start\n",
    "    shuffle=True,\n",
    "    num_workers=0,           # <-- key\n",
    "    pin_memory=False,        # pinning helps GPU, can slow CPU-only\n",
    "    persistent_workers=False # <-- key\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,                  # same dataset as before\n",
    "    batch_size=8,           # same batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,           # <-- disable multiprocessing\n",
    "    pin_memory=False,        # <-- you're likely on CPU\n",
    "    persistent_workers=False # <-- avoid stale worker pool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a0891d6-b11d-4dfa-af82-49a73d85b3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "batch 2631\n",
      "end of epoch in 4862.3 s\n"
     ]
    }
   ],
   "source": [
    "print('begin training')\n",
    "model.train()\n",
    "t0 = time.time()\n",
    "\n",
    "for batch_i, (imgs, masks) in enumerate(train_dl, 1):\n",
    "    print(f\"\\rbatch {batch_i}\", end='', flush=True)  # prints as soon as first batch arrives\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "    logits = model(imgs)\n",
    "    loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "print(\"\\nend of epoch in\", round(time.time()-t0, 1), \"s\")\n",
    "torch.save({\"model\": model.state_dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149b802-0a32-4a2a-a64e-8a9ec983cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55fe8c-6efb-4d3c-aec9-33fca8b7f3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "print('begin evaluation')\n",
    "model.eval()\n",
    "t0 = time.time()\n",
    "v_loss = 0.0; v_iou = 0.0; n = 0\n",
    "with torch.no_grad():\n",
    "    i=1\n",
    "    for imgs, masks in val_dl:\n",
    "        print(f\"\\rbatch {i}\", end='', flush=True)\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        logits = model(imgs)\n",
    "        v_loss += (0.5*bce(logits, masks) + 0.5*dice(logits, masks)).item()\n",
    "        v_iou  += iou_binary(logits, masks)\n",
    "        n += 1\n",
    "        i+=1\n",
    "v_loss /= n; v_iou /= n\n",
    "sched.step()\n",
    "print(f\"Epoch {ep:02d}  val_loss={v_loss:.4f}  val_IoU={v_iou:.4f}\")\n",
    "print(\"\\nend of epoch in\", round(time.time()-t0, 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b104a2-bae7-4624-9bd0-3be14f9ade14",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for ep in range(1, epochs+1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    for imgs, masks in train_dl:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    # --- validate ---\n",
    "    model.eval()\n",
    "    v_loss = 0.0; v_iou = 0.0; n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_dl:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            v_loss += (0.5*bce(logits, masks) + 0.5*dice(logits, masks)).item()\n",
    "            v_iou  += iou_binary(logits, masks)\n",
    "            n += 1\n",
    "    v_loss /= n; v_iou /= n\n",
    "    sched.step()\n",
    "    print(f\"Epoch {ep:02d}  val_loss={v_loss:.4f}  val_IoU={v_iou:.4f}\")\n",
    "\n",
    "    if v_iou > best_iou:\n",
    "        best_iou = v_iou\n",
    "        torch.save({\"model\": model.state_dict()}, best_path)\n",
    "\n",
    "print(f\"Best IoU: {best_iou:.4f}  -> saved {best_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e39b9a-9b1c-42d9-a930-b15d94bce0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 6) Load best model and evaluate on validation set =====\n",
    "print(\"\\nLoading best model for final evaluation...\")\n",
    "checkpoint = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "ious, dices = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in val_dl:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()\n",
    "        inter = (preds * masks).sum(dim=(1,2,3))\n",
    "        union = (preds + masks - preds*masks).sum(dim=(1,2,3))\n",
    "        dice  = (2*inter / (preds.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3)) + 1e-6))\n",
    "        iou   = (inter + 1e-6) / (union + 1e-6)\n",
    "        ious.extend(iou.cpu().numpy())\n",
    "        dices.extend(dice.cpu().numpy())\n",
    "\n",
    "final_iou = np.mean(ious)\n",
    "final_dice = np.mean(dices)\n",
    "print(f\"✅ Final Validation IoU:  {final_iou:.4f}\")\n",
    "print(f\"✅ Final Validation Dice: {final_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e10b377-753c-4309-a329-b926215ff6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg load  : 0.214s  | avg fwd : 0.913s  | avg bwd : 1.851s\n"
     ]
    }
   ],
   "source": [
    "load_t = fwd_t = bwd_t = 0.0\n",
    "N = 50  # measure first 50 batches\n",
    "\n",
    "it = iter(train_dl)\n",
    "for i in range(1, N+1):\n",
    "    t0 = time.time()\n",
    "    imgs, masks = next(it)     # load\n",
    "    load_t += time.time() - t0\n",
    "\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "    t1 = time.time()\n",
    "    logits = model(imgs)       # forward\n",
    "    loss = 0.5*bce(logits, masks) + 0.5*dice(logits, masks)\n",
    "    fwd_t += time.time() - t1\n",
    "\n",
    "    t2 = time.time()\n",
    "    opt.zero_grad(); loss.backward(); opt.step()  # backward\n",
    "    bwd_t += time.time() - t2\n",
    "\n",
    "print(f\"avg load  : {load_t/N:.3f}s  | avg fwd : {fwd_t/N:.3f}s  | avg bwd : {bwd_t/N:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9283e-55be-4ed3-9239-626c9e8e977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "load_t=fwd_t=bwd_t=0.0\n",
    "it = iter(train_dl)\n",
    "N = min(50, len(train_dl))\n",
    "for i in range(1, N+1):\n",
    "    t0=time.time(); imgs, masks = next(it); load_t += time.time()-t0\n",
    "    t1=time.time(); logits = model(imgs); loss = criterion(logits, masks); fwd_t += time.time()-t1\n",
    "    t2=time.time(); opt.zero_grad(); loss.backward(); opt.step(); bwd_t += time.time()-t2\n",
    "print(f\"avg load: {load_t/N:.3f}s | avg fwd: {fwd_t/N:.3f}s | avg bwd: {bwd_t/N:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea60a48-d89e-4d87-a924-1dfaaca99fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
